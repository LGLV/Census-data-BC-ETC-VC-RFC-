{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we use bagging classifier, extra tree classifier, voting classifier and random forest classifier on census data\n",
    "\n",
    "### Loading the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lglv\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "### Loading the needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/LGLV/ML_Census-Income/main/CensusIncome.scv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>77516</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>83311</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>215646</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>234721</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>160187</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24415</th>\n",
       "      <td>32552</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>84661</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24416</th>\n",
       "      <td>32553</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>116138</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24417</th>\n",
       "      <td>32557</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>154374</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24418</th>\n",
       "      <td>32558</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>151910</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24419</th>\n",
       "      <td>32559</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>201490</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24420 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  age  workclass  fnlwgt  education  education-num  \\\n",
       "0               0   39          6   77516          9             13   \n",
       "1               1   50          5   83311          9             13   \n",
       "2               2   38          3  215646         11              9   \n",
       "3               3   53          3  234721          1              7   \n",
       "4               6   49          3  160187          6              5   \n",
       "...           ...  ...        ...     ...        ...            ...   \n",
       "24415       32552   43          3   84661          8             11   \n",
       "24416       32553   32          3  116138         12             14   \n",
       "24417       32557   40          3  154374         11              9   \n",
       "24418       32558   58          3  151910         11              9   \n",
       "24419       32559   22          3  201490         11              9   \n",
       "\n",
       "       marital-status  occupation  relationship  race  sex  capital-gain  \\\n",
       "0                   4           0             1     4    1          2174   \n",
       "1                   2           3             0     4    1             0   \n",
       "2                   0           5             1     4    1             0   \n",
       "3                   2           5             0     2    1             0   \n",
       "4                   3           7             1     2    0             0   \n",
       "...               ...         ...           ...   ...  ...           ...   \n",
       "24415               2          11             0     4    1             0   \n",
       "24416               4          12             1     1    1             0   \n",
       "24417               2           6             0     4    1             0   \n",
       "24418               6           0             4     4    0             0   \n",
       "24419               4           0             3     4    1             0   \n",
       "\n",
       "       capital-loss  hours-per-week  native-country  income  \n",
       "0                 0              40              38       0  \n",
       "1                 0              13              38       0  \n",
       "2                 0              40              38       0  \n",
       "3                 0              40              38       0  \n",
       "4                 0              16              22       0  \n",
       "...             ...             ...             ...     ...  \n",
       "24415             0              45              38       0  \n",
       "24416             0              11              35       0  \n",
       "24417             0              40              38       1  \n",
       "24418             0              40              38       0  \n",
       "24419             0              20              38       0  \n",
       "\n",
       "[24420 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(url)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>24420.0</td>\n",
       "      <td>16306.316503</td>\n",
       "      <td>9376.263408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8196.75</td>\n",
       "      <td>16327.5</td>\n",
       "      <td>24419.25</td>\n",
       "      <td>32559.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>24420.0</td>\n",
       "      <td>39.123669</td>\n",
       "      <td>13.759997</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>48.00</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>24420.0</td>\n",
       "      <td>3.102334</td>\n",
       "      <td>1.109790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fnlwgt</th>\n",
       "      <td>24420.0</td>\n",
       "      <td>143041.703153</td>\n",
       "      <td>57259.295327</td>\n",
       "      <td>12285.0</td>\n",
       "      <td>103323.00</td>\n",
       "      <td>152087.5</td>\n",
       "      <td>189803.75</td>\n",
       "      <td>237044.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>24420.0</td>\n",
       "      <td>10.357740</td>\n",
       "      <td>3.806355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education-num</th>\n",
       "      <td>24420.0</td>\n",
       "      <td>10.140377</td>\n",
       "      <td>2.528812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital-status</th>\n",
       "      <td>24420.0</td>\n",
       "      <td>2.588943</td>\n",
       "      <td>1.513468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>24420.0</td>\n",
       "      <td>6.124816</td>\n",
       "      <td>3.964974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>24420.0</td>\n",
       "      <td>1.448608</td>\n",
       "      <td>1.617486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>24420.0</td>\n",
       "      <td>3.682310</td>\n",
       "      <td>0.847989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>24420.0</td>\n",
       "      <td>0.659664</td>\n",
       "      <td>0.473832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-gain</th>\n",
       "      <td>24420.0</td>\n",
       "      <td>1082.742957</td>\n",
       "      <td>7385.309024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-loss</th>\n",
       "      <td>24420.0</td>\n",
       "      <td>89.203071</td>\n",
       "      <td>408.210289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours-per-week</th>\n",
       "      <td>24420.0</td>\n",
       "      <td>40.487305</td>\n",
       "      <td>12.427038</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>45.00</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native-country</th>\n",
       "      <td>24420.0</td>\n",
       "      <td>36.596806</td>\n",
       "      <td>5.812635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.00</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>24420.0</td>\n",
       "      <td>0.245332</td>\n",
       "      <td>0.430293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count           mean           std      min        25%  \\\n",
       "Unnamed: 0      24420.0   16306.316503   9376.263408      0.0    8196.75   \n",
       "age             24420.0      39.123669     13.759997     17.0      28.00   \n",
       "workclass       24420.0       3.102334      1.109790      0.0       3.00   \n",
       "fnlwgt          24420.0  143041.703153  57259.295327  12285.0  103323.00   \n",
       "education       24420.0      10.357740      3.806355      0.0       9.00   \n",
       "education-num   24420.0      10.140377      2.528812      1.0       9.00   \n",
       "marital-status  24420.0       2.588943      1.513468      0.0       2.00   \n",
       "occupation      24420.0       6.124816      3.964974      0.0       3.00   \n",
       "relationship    24420.0       1.448608      1.617486      0.0       0.00   \n",
       "race            24420.0       3.682310      0.847989      0.0       4.00   \n",
       "sex             24420.0       0.659664      0.473832      0.0       0.00   \n",
       "capital-gain    24420.0    1082.742957   7385.309024      0.0       0.00   \n",
       "capital-loss    24420.0      89.203071    408.210289      0.0       0.00   \n",
       "hours-per-week  24420.0      40.487305     12.427038      1.0      40.00   \n",
       "native-country  24420.0      36.596806      5.812635      0.0      38.00   \n",
       "income          24420.0       0.245332      0.430293      0.0       0.00   \n",
       "\n",
       "                     50%        75%       max  \n",
       "Unnamed: 0       16327.5   24419.25   32559.0  \n",
       "age                 38.0      48.00      90.0  \n",
       "workclass            3.0       3.00       7.0  \n",
       "fnlwgt          152087.5  189803.75  237044.0  \n",
       "education           11.0      12.00      15.0  \n",
       "education-num       10.0      13.00      16.0  \n",
       "marital-status       2.0       4.00       6.0  \n",
       "occupation           6.0       9.00      13.0  \n",
       "relationship         1.0       3.00       5.0  \n",
       "race                 4.0       4.00       4.0  \n",
       "sex                  1.0       1.00       1.0  \n",
       "capital-gain         0.0       0.00   99999.0  \n",
       "capital-loss         0.0       0.00    4356.0  \n",
       "hours-per-week      40.0      45.00      99.0  \n",
       "native-country      38.0      38.00      40.0  \n",
       "income               0.0       0.00       1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting in X and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>77516</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>83311</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>215646</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>234721</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>160187</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24415</th>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>84661</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24416</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>116138</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24417</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>154374</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24418</th>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>151910</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24419</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>201490</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24420 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  fnlwgt  education  education-num  marital-status  \\\n",
       "0       39          6   77516          9             13               4   \n",
       "1       50          5   83311          9             13               2   \n",
       "2       38          3  215646         11              9               0   \n",
       "3       53          3  234721          1              7               2   \n",
       "4       49          3  160187          6              5               3   \n",
       "...    ...        ...     ...        ...            ...             ...   \n",
       "24415   43          3   84661          8             11               2   \n",
       "24416   32          3  116138         12             14               4   \n",
       "24417   40          3  154374         11              9               2   \n",
       "24418   58          3  151910         11              9               6   \n",
       "24419   22          3  201490         11              9               4   \n",
       "\n",
       "       occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
       "0               0             1     4    1          2174             0   \n",
       "1               3             0     4    1             0             0   \n",
       "2               5             1     4    1             0             0   \n",
       "3               5             0     2    1             0             0   \n",
       "4               7             1     2    0             0             0   \n",
       "...           ...           ...   ...  ...           ...           ...   \n",
       "24415          11             0     4    1             0             0   \n",
       "24416          12             1     1    1             0             0   \n",
       "24417           6             0     4    1             0             0   \n",
       "24418           0             4     4    0             0             0   \n",
       "24419           0             3     4    1             0             0   \n",
       "\n",
       "       hours-per-week  native-country  \n",
       "0                  40              38  \n",
       "1                  13              38  \n",
       "2                  40              38  \n",
       "3                  40              38  \n",
       "4                  16              22  \n",
       "...               ...             ...  \n",
       "24415              45              38  \n",
       "24416              11              35  \n",
       "24417              40              38  \n",
       "24418              40              38  \n",
       "24419              20              38  \n",
       "\n",
       "[24420 rows x 14 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:,1:-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "24415    0\n",
       "24416    0\n",
       "24417    1\n",
       "24418    0\n",
       "24419    0\n",
       "Name: income, Length: 24420, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.income\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data in train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X train is: (16361, 14)\n",
      "The shape of y train is: (16361,)\n",
      "The shape of X test is: (8059, 14)\n",
      "The shape of y test is: (8059,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print('The shape of X train is:', X_train.shape)\n",
    "print('The shape of y train is:', y_train.shape)\n",
    "print('The shape of X test is:', X_test.shape)\n",
    "print('The shape of y test is:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_esc = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_esc = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training 4 classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, VotingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score\n",
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " BAGC scores\n",
      "0.8378210696116144\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.90      6030\n",
      "           1       0.73      0.56      0.63      2029\n",
      "\n",
      "    accuracy                           0.84      8059\n",
      "   macro avg       0.80      0.75      0.77      8059\n",
      "weighted avg       0.83      0.84      0.83      8059\n",
      "\n",
      "[[5616  414]\n",
      " [ 893 1136]]\n",
      "**************************************************************************************************** \n",
      "\n",
      "\n",
      " ETC scores\n",
      "0.8404268519667453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.90      6030\n",
      "           1       0.72      0.59      0.65      2029\n",
      "\n",
      "    accuracy                           0.84      8059\n",
      "   macro avg       0.80      0.76      0.77      8059\n",
      "weighted avg       0.83      0.84      0.83      8059\n",
      "\n",
      "[[5572  458]\n",
      " [ 828 1201]]\n",
      "**************************************************************************************************** \n",
      "\n",
      "\n",
      " RFC scores\n",
      "0.8484923687802457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      6030\n",
      "           1       0.75      0.60      0.67      2029\n",
      "\n",
      "    accuracy                           0.85      8059\n",
      "   macro avg       0.81      0.77      0.78      8059\n",
      "weighted avg       0.84      0.85      0.84      8059\n",
      "\n",
      "[[5626  404]\n",
      " [ 817 1212]]\n",
      "**************************************************************************************************** \n",
      "\n",
      "\n",
      " VC scores\n",
      "0.8463829259213302\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      6030\n",
      "           1       0.74      0.59      0.66      2029\n",
      "\n",
      "    accuracy                           0.85      8059\n",
      "   macro avg       0.81      0.76      0.78      8059\n",
      "weighted avg       0.84      0.85      0.84      8059\n",
      "\n",
      "[[5615  415]\n",
      " [ 823 1206]]\n",
      "**************************************************************************************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets create a Predictive Models\n",
    "\n",
    "model_accuracy = pd.DataFrame(columns=['Model'])\n",
    "models = {\n",
    "    \"BAGC\" : BaggingClassifier(),\n",
    "    \"ETC\" : ExtraTreesClassifier(),\n",
    "    \"RFC\" : RandomForestClassifier(),\n",
    "    \"VC\" : VotingClassifier([('BAGC', BaggingClassifier()), ('ETC', ExtraTreesClassifier()), ('RFC', RandomForestClassifier())])\n",
    "    }\n",
    "\n",
    "for abrev, model in models.items():\n",
    "    \n",
    "    model.fit(X_train_esc, y_train)\n",
    "    \n",
    "    # score = model.score(X_train_esc, y_train) # Training score\n",
    "        \n",
    "    y_pred = model.predict(X_test_esc)\n",
    "    \n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    train_pred = model.predict(X_train_esc)\n",
    "    train_acc = accuracy_score(y_train, train_pred)\n",
    "    print(\"\\n\", abrev + ' scores')\n",
    "    print(acc)\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print('*' * 100,\"\\n\")\n",
    "    model_accuracy = model_accuracy.append({'Model': abrev, 'Accuracy': acc, 'Train_acc': train_acc}, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Train_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RFC</td>\n",
       "      <td>0.848492</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VC</td>\n",
       "      <td>0.846383</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ETC</td>\n",
       "      <td>0.840427</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAGC</td>\n",
       "      <td>0.837821</td>\n",
       "      <td>0.985453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy  Train_acc\n",
       "2   RFC  0.848492   1.000000\n",
       "3    VC  0.846383   1.000000\n",
       "1   ETC  0.840427   1.000000\n",
       "0  BAGC  0.837821   0.985453"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_accuracy.sort_values(ascending=False, by = 'Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling all independent features before train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scal = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00898777,  2.6110572 , -1.14439139, ..., -0.21852682,\n",
       "        -0.03921413,  0.24140906],\n",
       "       [ 0.79044741,  1.70996738, -1.04318305, ..., -0.21852682,\n",
       "        -2.21194053,  0.24140906],\n",
       "       [-0.08166369, -0.09221226,  1.26801741, ..., -0.21852682,\n",
       "        -0.03921413,  0.24140906],\n",
       "       ...,\n",
       "       [ 0.06368816, -0.09221226,  0.19791597, ..., -0.21852682,\n",
       "        -0.03921413,  0.24140906],\n",
       "       [ 1.37185481, -0.09221226,  0.15488277, ..., -0.21852682,\n",
       "        -0.03921413,  0.24140906],\n",
       "       [-1.24447849, -0.09221226,  1.02078611, ..., -0.21852682,\n",
       "        -1.64864109,  0.24140906]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled = std_scal.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling inmbalenced target\n",
    "### Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(sampling_strategy=1) # Numerical value\n",
    "# rus = RandomUnderSampler(sampling_strategy=\"not minority\") # String\n",
    "X_res, y_res = rus.fit_resample(X_scaled, y)\n",
    "\n",
    "ax = y_res.value_counts().plot.pie(autopct='%.2f')\n",
    "_ = ax.set_title(\"Under-sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5991\n",
       "1    5991\n",
       "Name: income, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18429\n",
       "1     5991\n",
       "Name: income, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data in train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The X_train_us shape is: (9585, 14)\n",
      "The X_test_us shape is: (2397, 14)\n",
      "The y_train_us shape is: (9585,)\n",
      "The y_test_us shape is: (2397,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_us, X_test_us, y_train_us, y_test_us = train_test_split(X_res, y_res, test_size = 0.20, random_state=42)\n",
    "print('The X_train_us shape is:', X_train_us.shape)\n",
    "print('The X_test_us shape is:', X_test_us.shape)\n",
    "print('The y_train_us shape is:', y_train_us.shape)\n",
    "print('The y_test_us shape is:', y_test_us.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " BAGC scores\n",
      "0.7901543596161869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1227\n",
      "           1       0.78      0.80      0.79      1170\n",
      "\n",
      "    accuracy                           0.79      2397\n",
      "   macro avg       0.79      0.79      0.79      2397\n",
      "weighted avg       0.79      0.79      0.79      2397\n",
      "\n",
      "[[962 265]\n",
      " [238 932]]\n",
      "**************************************************************************************************** \n",
      "\n",
      "\n",
      " ETC scores\n",
      "0.799749687108886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.80      1227\n",
      "           1       0.77      0.84      0.80      1170\n",
      "\n",
      "    accuracy                           0.80      2397\n",
      "   macro avg       0.80      0.80      0.80      2397\n",
      "weighted avg       0.80      0.80      0.80      2397\n",
      "\n",
      "[[936 291]\n",
      " [189 981]]\n",
      "**************************************************************************************************** \n",
      "\n",
      "\n",
      " RFC scores\n",
      "0.799749687108886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.80      1227\n",
      "           1       0.77      0.84      0.80      1170\n",
      "\n",
      "    accuracy                           0.80      2397\n",
      "   macro avg       0.80      0.80      0.80      2397\n",
      "weighted avg       0.80      0.80      0.80      2397\n",
      "\n",
      "[[937 290]\n",
      " [190 980]]\n",
      "**************************************************************************************************** \n",
      "\n",
      "\n",
      " VC scores\n",
      "0.803087192323738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.77      0.80      1227\n",
      "           1       0.78      0.84      0.81      1170\n",
      "\n",
      "    accuracy                           0.80      2397\n",
      "   macro avg       0.80      0.80      0.80      2397\n",
      "weighted avg       0.80      0.80      0.80      2397\n",
      "\n",
      "[[948 279]\n",
      " [193 977]]\n",
      "**************************************************************************************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets create a Predictive Models\n",
    "\n",
    "model_accuracy = pd.DataFrame(columns=['Model'])\n",
    "models = {\n",
    "    \"BAGC\" : BaggingClassifier(),\n",
    "    \"ETC\" : ExtraTreesClassifier(),\n",
    "    \"RFC\" : RandomForestClassifier(),\n",
    "    \"VC\" : VotingClassifier([('BAGC', BaggingClassifier()), ('ETC', ExtraTreesClassifier()), ('RFC', RandomForestClassifier())])\n",
    "    }\n",
    "\n",
    "for abrev, model in models.items():\n",
    "    \n",
    "    model.fit(X_train_us, y_train_us)\n",
    "    \n",
    "    # score = model.score(X_train_esc, y_train) # Training score\n",
    "        \n",
    "    y_pred_us = model.predict(X_test_us)\n",
    "    \n",
    "    acc = accuracy_score(y_test_us,y_pred_us)\n",
    "    train_pred = model.predict(X_train_us)\n",
    "    train_acc = accuracy_score(y_train_us, train_pred)\n",
    "    print(\"\\n\", abrev + ' scores')\n",
    "    print(acc)\n",
    "    print(classification_report(y_test_us,y_pred_us))\n",
    "    print(confusion_matrix(y_test_us,y_pred_us))\n",
    "    print('*' * 100,\"\\n\")\n",
    "    model_accuracy = model_accuracy.append({'Model': abrev, 'Accuracy': acc, 'Train_acc': train_acc}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Train_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ETC</td>\n",
       "      <td>0.799750</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RFC</td>\n",
       "      <td>0.799750</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VC</td>\n",
       "      <td>0.803087</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAGC</td>\n",
       "      <td>0.790154</td>\n",
       "      <td>0.986437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy  Train_acc\n",
       "1   ETC  0.799750   1.000000\n",
       "2   RFC  0.799750   1.000000\n",
       "3    VC  0.803087   1.000000\n",
       "0  BAGC  0.790154   0.986437"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_accuracy.sort_values(ascending=False, by = 'Train_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#ros = RandomOverSampler(sampling_strategy=1) # Float\n",
    "ros = RandomOverSampler(sampling_strategy=\"not majority\") # String\n",
    "X_res_over, y_res_over = ros.fit_resample(X_scaled, y)\n",
    "\n",
    "ax = y_res_over.value_counts().plot.pie(autopct='%.2f')\n",
    "_ = ax.set_title(\"Over-sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18429\n",
       "1    18429\n",
       "Name: income, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res_over.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18429\n",
       "1     5991\n",
       "Name: income, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data in train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The X_train_overs shape is: (29486, 14)\n",
      "The X_test_overs shape is: (7372, 14)\n",
      "The y_train_overs shape is: (29486,)\n",
      "The y_test_overs shape is: (7372,)\n"
     ]
    }
   ],
   "source": [
    "X_train_overs, X_test_overs, y_train_overs, y_test_overs = train_test_split(X_res_over, y_res_over, test_size = 0.2, random_state=42)\n",
    "print('The X_train_overs shape is:', X_train_overs.shape)\n",
    "print('The X_test_overs shape is:', X_test_overs.shape)\n",
    "print('The y_train_overs shape is:', y_train_overs.shape)\n",
    "print('The y_test_overs shape is:', y_test_overs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " BAGC scores\n",
      "0.9183396635919696\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91      3640\n",
      "           1       0.89      0.95      0.92      3732\n",
      "\n",
      "    accuracy                           0.92      7372\n",
      "   macro avg       0.92      0.92      0.92      7372\n",
      "weighted avg       0.92      0.92      0.92      7372\n",
      "\n",
      "[[3209  431]\n",
      " [ 171 3561]]\n",
      "**************************************************************************************************** \n",
      "\n",
      "\n",
      " ETC scores\n",
      "0.9305480195333695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      3640\n",
      "           1       0.91      0.96      0.93      3732\n",
      "\n",
      "    accuracy                           0.93      7372\n",
      "   macro avg       0.93      0.93      0.93      7372\n",
      "weighted avg       0.93      0.93      0.93      7372\n",
      "\n",
      "[[3274  366]\n",
      " [ 146 3586]]\n",
      "**************************************************************************************************** \n",
      "\n",
      "\n",
      " RFC scores\n",
      "0.9245794899620184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92      3640\n",
      "           1       0.89      0.97      0.93      3732\n",
      "\n",
      "    accuracy                           0.92      7372\n",
      "   macro avg       0.93      0.92      0.92      7372\n",
      "weighted avg       0.93      0.92      0.92      7372\n",
      "\n",
      "[[3206  434]\n",
      " [ 122 3610]]\n",
      "**************************************************************************************************** \n",
      "\n",
      "\n",
      " VC scores\n",
      "0.9276994031470429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92      3640\n",
      "           1       0.90      0.96      0.93      3732\n",
      "\n",
      "    accuracy                           0.93      7372\n",
      "   macro avg       0.93      0.93      0.93      7372\n",
      "weighted avg       0.93      0.93      0.93      7372\n",
      "\n",
      "[[3240  400]\n",
      " [ 133 3599]]\n",
      "**************************************************************************************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets create a Predictive Models\n",
    "\n",
    "model_accuracy = pd.DataFrame(columns=['Model'])\n",
    "models = {\n",
    "    \"BAGC\" : BaggingClassifier(),\n",
    "    \"ETC\" : ExtraTreesClassifier(),\n",
    "    \"RFC\" : RandomForestClassifier(),\n",
    "    \"VC\" : VotingClassifier([('BAGC', BaggingClassifier()), ('ETC', ExtraTreesClassifier()), ('RFC', RandomForestClassifier())])\n",
    "    }\n",
    "\n",
    "for abrev, model in models.items():\n",
    "    \n",
    "    model.fit(X_train_overs, y_train_overs)\n",
    "    \n",
    "    # score = model.score(X_train_esc, y_train) # Training score\n",
    "        \n",
    "    y_pred_overs = model.predict(X_test_overs)\n",
    "    \n",
    "    acc = accuracy_score(y_test_overs, y_pred_overs)\n",
    "    train_pred_overs = model.predict(X_train_overs)\n",
    "    train_acc_overs = accuracy_score(y_train_overs, train_pred_overs)\n",
    "    print(\"\\n\", abrev + ' scores')\n",
    "    print(acc)\n",
    "    print(classification_report(y_test_overs, y_pred_overs))\n",
    "    print(confusion_matrix(y_test_overs, y_pred_overs))\n",
    "    print('*' * 100,\"\\n\")\n",
    "    model_accuracy = model_accuracy.append({'Model': abrev, 'Accuracy': acc, 'Train_acc': train_acc}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Train_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAGC</td>\n",
       "      <td>0.918340</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ETC</td>\n",
       "      <td>0.930548</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RFC</td>\n",
       "      <td>0.924579</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VC</td>\n",
       "      <td>0.927699</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy  Train_acc\n",
       "0  BAGC  0.918340        1.0\n",
       "1   ETC  0.930548        1.0\n",
       "2   RFC  0.924579        1.0\n",
       "3    VC  0.927699        1.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_accuracy.sort_values(ascending=False, by = 'Train_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions \n",
    "\n",
    "Comparing the models between Undersampling, Oversampling and inmbalenced data. \n",
    "\n",
    "* Oversamplig example, ovefits in all the models tested.\n",
    "\n",
    "Between the Undersampling and inmbalenced data models:\n",
    "* In Undersampling data models the one that did not ovefits was BaggingClassifier with:    \n",
    "    Accuracy of: 0.790154    \n",
    "    Training accuracy of: 0.986437 \n",
    "    \n",
    "    \n",
    "* In inmbalenced data models the one that did not ovefits was BaggingClassifier with:  \n",
    "    Accuracy of: 0.837821 \t \n",
    "    Training accuracy of: 0.985453\n",
    "\n",
    "### Thus, we recomend to use the inmbalenced data to make predictions of census data.\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
